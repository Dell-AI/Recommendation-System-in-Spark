{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for Content Based Filtering with GBT and Random Forest for 1M rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialization\n",
    "import os\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "\n",
    "# spark imports\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# data science imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Read in data through spark since the data is sored in hadoop and format the columns\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SQLContext, Row\n",
    "from pyspark.sql.functions import *\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "# Spark model imports\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, DecisionTreeClassificationModel\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "from pyspark.ml.classification import RandomForestClassifier, RandomForestClassificationModel\n",
    "\n",
    "from pyspark.ml.regression import RandomForestRegressor, RandomForestRegressionModel\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "from pyspark.ml.regression import GBTRegressor, GBTRegressionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'hdfs:///user/andrew/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sdf indicates spark dataframe\n",
    "movies_sdf = sqlContext.read.parquet(data_path + 'movie_metadata_OHE_subset')\n",
    "users_full_sdf = sqlContext.read.parquet(data_path + 'users_metadata') \n",
    "users_full_sdf = users_full_sdf.na.fill(0)\n",
    "\n",
    "Rating = Row(\"user_id\", \"item_id\", \"label\") # Ignore timestamp\n",
    "ratings = sc.textFile(data_path + 'ratings.dat')\\\n",
    "    .map(lambda line: line.split(\"::\")[0:3])\\\n",
    "    .map(lambda line: map(int, line))\\\n",
    "    .map(lambda r: Rating(*r))\n",
    "ratings_sdf = sqlContext.createDataFrame(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the full ratings with the movies' profile data, then add the users' profile data\n",
    "ratings_metadata_sdf = ratings_sdf.join(movies_sdf, ['item_id'])\n",
    "\n",
    "ratings_muf_sdf = ratings_metadata_sdf.join(users_full_sdf, ['user_id']) \\\n",
    "        .drop('user_id', 'item_id', 'title', 'imdb_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the full ratings with movie and user metadata to a dataframe of label and features\n",
    "ratings_muf_rdd = ratings_muf_sdf.rdd.map(lambda x: (x[0], Vectors.dense(x[1:])))\n",
    "ratings_muf_sdf_2 = sqlContext.createDataFrame(ratings_muf_rdd, schema = ['label', 'features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test sets\n",
    "rmuf_sdf_train, rmuf_sdf_test = ratings_muf_sdf_2.randomSplit([0.75, 0.25], seed = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata and Full User Data\n",
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train a single decision tree with a depth of 30\n",
    "dtc  = DecisionTreeClassifier(maxDepth=30, labelCol=\"label\", seed=42, maxMemoryInMB = 8192)\n",
    "dtc_model = dtc.fit(rmuf_sdf_train)\n",
    "dtc_model.featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Make predictions on the test set\n",
    "dtc_model_preds = dtc_model.transform(rmuf_sdf_test)\n",
    "dtc_model_preds.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Evaluate the test set predictions\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "print 'f1 score:', evaluator.evaluate(dtc_model_preds)\n",
    "print 'Weighted Precision score:', evaluator.evaluate(dtc_model_preds, {evaluator.metricName: \"weightedPrecision\"})\n",
    "print 'Weighted Recall score:', evaluator.evaluate(dtc_model_preds, {evaluator.metricName: \"weightedRecall\"})\n",
    "print 'Accuracy:', evaluator.evaluate(dtc_model_preds, {evaluator.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train a Random Forest Classifier with 100 trees with depth of 30\n",
    "rfc  = RandomForestClassifier(numTrees=100, maxDepth=30, \n",
    "                              labelCol=\"label\", seed=42, \n",
    "                              maxMemoryInMB= 1024, \n",
    "                              featureSubsetStrategy = 'auto',\n",
    "                              minInstancesPerNode = 20,\n",
    "                              # minInfoGain = ?,\n",
    "                              subsamplingRate = 0.6,\n",
    "                              maxBins = 5)\n",
    "rfc_model = rfc.fit(rmuf_sdf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Make predictions on the test set\n",
    "rfc_model_preds = rfc_model.transform(rmuf_sdf_test)\n",
    "rfc_model_preds.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Evaluate the test set predictions\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "print 'f1 score:', evaluator.evaluate(rfc_model_preds)\n",
    "print 'Weighted Precision score:', evaluator.evaluate(rfc_model_preds, {evaluator.metricName: \"weightedPrecision\"})\n",
    "print 'Weighted Recall score:', evaluator.evaluate(rfc_model_preds, {evaluator.metricName: \"weightedRecall\"})\n",
    "print 'Accuracy:', evaluator.evaluate(rfc_model_preds, {evaluator.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train a Random Forest Regressor with a 100 trees with depth of 30\n",
    "rfr  = RandomForestRegressor(numTrees=100, maxDepth=30, \n",
    "                              labelCol=\"label\", seed=42, \n",
    "                              maxMemoryInMB= 1024, \n",
    "                              featureSubsetStrategy = 'auto',\n",
    "                              minInstancesPerNode = 20,\n",
    "                              # minInfoGain = ?,\n",
    "                              subsamplingRate = 0.6)\n",
    "rfr_model = rfr.fit(rmuf_sdf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Make predictions on the test set\n",
    "rfr_model_preds = rfr_model.transform(rmuf_sdf_test)\n",
    "rfr_model_preds.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Evaluate the test set predictions\n",
    "evaluator = RegressionEvaluator(predictionCol=\"prediction\")\n",
    "print 'RMSE score:', evaluator.evaluate(rfr_model_preds)\n",
    "print 'R-squared:', evaluator.evaluate(rfr_model_preds, {evaluator.metricName: \"r2\"})\n",
    "print 'Mean Absolute Error:', evaluator.evaluate(rfr_model_preds, {evaluator.metricName: \"mae\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosted Tree Regressor\n",
    "##### Depth 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train a GBT Regressor with a depth of 30\n",
    "gbtr  = GBTRegressor(maxDepth=30, labelCol=\"label\", seed=42, subsamplingRate=0.7, stepSize = 0.1, maxMemoryInMB= 2048)\n",
    "gbtr_model = gbtr.fit(rmuf_sdf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Make predictions on the test set\n",
    "gbtr_model_preds = gbtr_model.transform(rmuf_sdf_test)\n",
    "gbtr_model_preds.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Evaluate the test set predictions\n",
    "evaluator = RegressionEvaluator(predictionCol=\"prediction\")\n",
    "print 'RMSE score:', evaluator.evaluate(gbtr_model_preds)\n",
    "print 'R-squared:', evaluator.evaluate(gbtr_model_preds, {evaluator.metricName: \"r2\"})\n",
    "print 'Mean Absolute Error:', evaluator.evaluate(gbtr_model_preds, {evaluator.metricName: \"mae\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Depth 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train a GBT Regressor with a depth of 10\n",
    "gbtr_2  = GBTRegressor(maxDepth=10, labelCol=\"label\", seed=42, stepSize = 0.1, maxMemoryInMB= 2048)\n",
    "gbtr_model_2 = gbtr_2.fit(rmuf_sdf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Make predictions on the test set\n",
    "gbtr_model_preds_2 = gbtr_model_2.transform(rmuf_sdf_test)\n",
    "gbtr_model_preds_2.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Evaluate the test set predictions\n",
    "evaluator = RegressionEvaluator(predictionCol=\"prediction\")\n",
    "print 'RMSE score:', evaluator.evaluate(gbtr_model_preds_2)\n",
    "print 'R-squared:', evaluator.evaluate(gbtr_model_preds_2, {evaluator.metricName: \"r2\"})\n",
    "print 'Mean Absolute Error:', evaluator.evaluate(gbtr_model_preds_2, {evaluator.metricName: \"mae\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and load model\n",
    "gbtr_model_2.save(data_path + 'GBTRegD10Model')\n",
    "sameModel = GBTRegressionModel.load(data_path + 'GBTRegD10Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Make predictions on the test set\n",
    "sameModel_preds_2 = sameModel.transform(rmuf_sdf_test)\n",
    "sameModel_preds_2.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Evaluate the loaded model's test set predictions\n",
    "evaluator = RegressionEvaluator(predictionCol=\"prediction\")\n",
    "print 'RMSE score:', evaluator.evaluate(sameModel_preds_2)\n",
    "print 'R-squared:', evaluator.evaluate(sameModel_preds_2, {evaluator.metricName: \"r2\"})\n",
    "print 'Mean Absolute Error:', evaluator.evaluate(sameModel_preds_2, {evaluator.metricName: \"mae\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Grid Search\n",
    "#### Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "# gbtr = GBTRegressor(seed = 42, maxMemoryInMB= 2048)\n",
    "# grid = ParamGridBuilder() \\\n",
    "#         .addGrid(gbtr.maxDepth, [10, 20]) \\\n",
    "#         .addGrid(gbtr.subsamplingRate, [0.6, 0.7]) \\\n",
    "#         .addGrid(gbtr.stepSize, [0.01, 0.05, 0.1]) \\\n",
    "#         .build()\n",
    "# evaluator = RegressionEvaluator(predictionCol=\"prediction\", metricName=\"mae\")\n",
    "# cv = CrossValidator(estimator=gbtr, estimatorParamMaps=grid, evaluator=evaluator, seed = 42)\n",
    "# cv_model = cv.fit(rmuf_sdf_train_2)\n",
    "# evaluator.evaluate(cv_model.transform(rmuf_sdf_train_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluator.evaluate(cv_model.transform(rmuf_sdf_test_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = [{p.name: v for p, v in m.items()} for m in cv_model.getEstimatorParamMaps()]\n",
    "# [ps.update({cv_model.getEvaluator().getMetricName(): metric}) for ps, metric in zip(params, cv_model.avgMetrics)]\n",
    "# params_df = pd.DataFrame(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print 'Best Parameters:'\n",
    "# params_df.iloc[np.where(np.argmin(params_df.metric))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
