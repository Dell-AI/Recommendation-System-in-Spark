{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDb Movie Metadata Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialization\n",
    "import os\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "\n",
    "# spark imports\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SQLContext, Row\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "# data science imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# data collection imports\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import ast\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'hdfs:///user/andrew/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import and collect movies data\n",
    "This includes the movieId, title, and genres provided in the Movie Lens data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read in data through spark since the data is sored in hadoop and format the columns\n",
    "# from pyspark.sql.types import *\n",
    "# from pyspark.sql import SQLContext, Row\n",
    "# sqlContext = SQLContext(sc)\n",
    "\n",
    "# movies = pd.read_csv('movies.csv', header = 0, dtype = {'movieId': 'int64', 'title': str, 'genres': str})\n",
    "# links = pd.read_csv('links.csv', header = 0, dtype = {'movieId': 'int64', 'imdbId': str, 'tmdbId': str})\n",
    "# ratings = pd.read_csv('ratings.csv', header = 0, dtype = {'userId': str, 'movieId': 'int64', 'rating': np.float64, 'timestamp': str})\n",
    "# movies2 = movies.merge(links[['movieId', 'imdbId']], left_on=['movieId'], right_on = ['movieId'], how = 'left')\n",
    "\n",
    "# movies_sdf = sqlContext.createDataFrame(movies2)\n",
    "# ratings_sdf = sqlContext.createDataFrame(ratings)\n",
    "\n",
    "# # write movies and ratings to parquet file\n",
    "# movies_sdf.write.format('parquet').mode('overwrite').save(data_path + 'movies_20m')\n",
    "# ratings_sdf.write.format('parquet').mode('overwrite').save(data_path + 'ratings_20m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>imdbId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66509</td>\n",
       "      <td>Funny People (2009)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "      <td>1201167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66511</td>\n",
       "      <td>Berlin Calling (2008)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "      <td>1213019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66513</td>\n",
       "      <td>Devil Hides in Doubt (Sollbruchstelle) (2008)</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>1322381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66517</td>\n",
       "      <td>Against the Dark (2009)</td>\n",
       "      <td>Action|Horror</td>\n",
       "      <td>1194271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66537</td>\n",
       "      <td>Letter for the King, The (Brief voor de koning...</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>0490377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>66539</td>\n",
       "      <td>Firepower (1979)</td>\n",
       "      <td>Action|Drama|Thriller</td>\n",
       "      <td>0079153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>66544</td>\n",
       "      <td>Nuremberg (2000)</td>\n",
       "      <td>Drama|War</td>\n",
       "      <td>0208629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>66547</td>\n",
       "      <td>Bigger Than Life (1956)</td>\n",
       "      <td>Drama|Mystery|Thriller</td>\n",
       "      <td>0049010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>66549</td>\n",
       "      <td>Going to Kansas City (1998)</td>\n",
       "      <td>Drama|Romance|Thriller</td>\n",
       "      <td>0119211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>66551</td>\n",
       "      <td>Red Sands (2009)</td>\n",
       "      <td>Action|Horror</td>\n",
       "      <td>1103256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                                              title  \\\n",
       "0    66509                                Funny People (2009)   \n",
       "1    66511                              Berlin Calling (2008)   \n",
       "2    66513      Devil Hides in Doubt (Sollbruchstelle) (2008)   \n",
       "3    66517                            Against the Dark (2009)   \n",
       "4    66537  Letter for the King, The (Brief voor de koning...   \n",
       "5    66539                                   Firepower (1979)   \n",
       "6    66544                                   Nuremberg (2000)   \n",
       "7    66547                            Bigger Than Life (1956)   \n",
       "8    66549                        Going to Kansas City (1998)   \n",
       "9    66551                                   Red Sands (2009)   \n",
       "\n",
       "                   genres   imdbId  \n",
       "0            Comedy|Drama  1201167  \n",
       "1            Comedy|Drama  1213019  \n",
       "2             Documentary  1322381  \n",
       "3           Action|Horror  1194271  \n",
       "4               Adventure  0490377  \n",
       "5   Action|Drama|Thriller  0079153  \n",
       "6               Drama|War  0208629  \n",
       "7  Drama|Mystery|Thriller  0049010  \n",
       "8  Drama|Romance|Thriller  0119211  \n",
       "9           Action|Horror  1103256  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in data through spark since the data is sored in hadoop and format the columns\n",
    "Item = Row('item_id', 'title' ,'genres', 'imdbId')\n",
    "\n",
    "movies = sqlContext.read.parquet(data_path + 'movies_20m')\n",
    "\n",
    "# Collect the data in a simple pandas data frame for easier manipulation\n",
    "movies_df = movies.toPandas()\n",
    "movies_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the OMDb API to collect more movie information\n",
    "def movie_metadata_extract(input_val, api_key = ''):\n",
    "    time.sleep(0.5)\n",
    "    title_val = input_val[0]\n",
    "    imdb_id = input_val[1]\n",
    "    \n",
    "    # remove the year from the title\n",
    "    title = title_val[0:-7]\n",
    "    title = title.split(' (')[0]\n",
    "    if title[-5:] == ', The':\n",
    "        title = 'The ' + title[0:-5]\n",
    "    elif title[-4:] == ', An':\n",
    "        title = 'An ' + title[0:-4]\n",
    "    elif title[-4:] == ', La':\n",
    "        title = 'La ' + title[0:-4]\n",
    "    elif title[-3:] == ', A':\n",
    "        title = 'A ' + title[0:-3]\n",
    "\n",
    "    year = title_val[-5:-1]\n",
    "    \n",
    "    if imdb_id == '':\n",
    "        imdb_id = 'tt' + imdb_id\n",
    "        movie_request = requests.get('http://www.omdbapi.com/?apikey=' + api_key, \n",
    "                                     {'i': imdb_id, 't': title, 'y': year})\n",
    "    else:\n",
    "        movie_request = requests.get('http://www.omdbapi.com/?apikey=' + api_key, \n",
    "                                     {'t': title, 'y': year})\n",
    "    movie_dict = ast.literal_eval(movie_request.text.encode('utf-8'))\n",
    "    \n",
    "    if movie_dict.get('Response') == 'True':\n",
    "        # Attempt to extract IMDb Rating\n",
    "        try:\n",
    "            imdb_rating = float(movie_dict.get('imdbRating'))\n",
    "        except:\n",
    "            imdb_rating = 0\n",
    "        # Attempt to extract IMDb Votes\n",
    "        try:\n",
    "            imdb_votes = int(movie_dict.get('imdbVotes').replace(',', ''))\n",
    "        except:\n",
    "            imdb_votes = 0\n",
    "        # Attempt to extract Metascore\n",
    "        try:\n",
    "            metascore = int(movie_dict.get('Metascore'))\n",
    "        except:\n",
    "            metascore = 0\n",
    "        # Attempt to extract Runtime\n",
    "        try:\n",
    "            runtime = int(movie_dict.get('Runtime')[0:-4].replace(',', ''))\n",
    "        except:\n",
    "            runtime = 0\n",
    "        # Attempt to extract Year\n",
    "        try:\n",
    "            year = int(movie_dict.get('Year'))\n",
    "        except:\n",
    "            year = 0\n",
    "        \n",
    "        genre_list = [unicodedata.normalize('NFKD', g.decode('utf-8')).encode('ascii', 'ignore') \n",
    "                      for g in movie_dict.get('Genre').split(', ')]\n",
    "        director_list = [unicodedata.normalize('NFKD', d.decode('utf-8')).encode('ascii', 'ignore') \n",
    "                         for d in movie_dict.get('Director').split(', ')]\n",
    "        director_list = [director.split('(')[0] for director in director_list]\n",
    "        actor_list = [unicodedata.normalize('NFKD', a.decode('utf-8')).encode('ascii', 'ignore') \n",
    "                      for a in movie_dict.get('Actors').split(', ')]\n",
    "        actor_list = [actor.split('(')[0] for actor in actor_list]\n",
    "\n",
    "        return(pd.Series([movie_dict.get('imdbID'), \n",
    "                          imdb_rating,\n",
    "                          imdb_votes,\n",
    "                          metascore,\n",
    "                          runtime,\n",
    "                          year,\n",
    "                          movie_dict.get('Rated'), \n",
    "                          genre_list,\n",
    "                          director_list,\n",
    "                          actor_list],\n",
    "                         index=['imdb_id', \n",
    "                                'imdb_rating', 'imdb_votes', \n",
    "                                'metascore', 'runtime', 'year',\n",
    "                                'MPAA_rating', 'imdb_genres', \n",
    "                                'director', 'actors']))\n",
    "    else:\n",
    "        text = title.replace('&', 'and') + ' ' + year + ' movie'\n",
    "        text = text.replace(' ', '+')\n",
    "\n",
    "        response = requests.get('https://google.com/search?q=' + text)\n",
    "\n",
    "        imdbID = ''\n",
    "        soup = BeautifulSoup(response.text)\n",
    "        for a in soup.find_all('a'):\n",
    "              if a.get('href')[0:34] == '/url?q=https://www.imdb.com/title/':\n",
    "                imdbID = a.get('href')[32:45].split('/')[1]\n",
    "                break\n",
    "                \n",
    "        movie_request = requests.get('http://www.omdbapi.com/?apikey=' + api_key, \n",
    "                                     {'i': imdbID})\n",
    "        movie_dict = ast.literal_eval(movie_request.text.encode('utf-8'))\n",
    "        if movie_dict.get('Response') == 'True':\n",
    "            # Attempt to extract IMDb Rating\n",
    "            try:\n",
    "                imdb_rating = float(movie_dict.get('imdbRating'))\n",
    "            except:\n",
    "                imdb_rating = 0\n",
    "            # Attempt to extract IMDb Votes\n",
    "            try:\n",
    "                imdb_votes = int(movie_dict.get('imdbVotes').replace(',', ''))\n",
    "            except:\n",
    "                imdb_votes = 0\n",
    "            # Attempt to extract Metascore\n",
    "            try:\n",
    "                metascore = int(movie_dict.get('Metascore'))\n",
    "            except:\n",
    "                metascore = 0\n",
    "            # Attempt to extract Runtime\n",
    "            try:\n",
    "                runtime = int(movie_dict.get('Runtime')[0:-4].replace(',', ''))\n",
    "            except:\n",
    "                runtime = 0\n",
    "            # Attempt to extract Year\n",
    "            try:\n",
    "                year = int(movie_dict.get('Year'))\n",
    "            except:\n",
    "                year = 0\n",
    "            \n",
    "            genre_list = [unicodedata.normalize('NFKD', g.decode('utf-8')).encode('ascii', 'ignore') \n",
    "                          for g in movie_dict.get('Genre').split(', ')]\n",
    "            director_list = [unicodedata.normalize('NFKD', d.decode('utf-8')).encode('ascii', 'ignore') \n",
    "                             for d in movie_dict.get('Director').split(', ')]\n",
    "            director_list = [director.split('(')[0] for director in director_list]\n",
    "            actor_list = [unicodedata.normalize('NFKD', a.decode('utf-8')).encode('ascii', 'ignore') \n",
    "                          for a in movie_dict.get('Actors').split(', ')]\n",
    "            actor_list = [actor.split('(')[0] for actor in actor_list]\n",
    "\n",
    "            return(pd.Series([movie_dict.get('imdbID'), \n",
    "                              imdb_rating,\n",
    "                              imdb_votes,\n",
    "                              metascore,\n",
    "                              runtime,\n",
    "                              year,\n",
    "                              movie_dict.get('Rated'), \n",
    "                              genre_list,\n",
    "                              director_list,\n",
    "                              actor_list],\n",
    "                             index=['imdb_id', \n",
    "                                    'imdb_rating', 'imdb_votes', \n",
    "                                    'metascore', 'runtime', 'year',\n",
    "                                    'MPAA_rating', 'imdb_genres', \n",
    "                                    'director', 'actors']))\n",
    "        \n",
    "        \n",
    "        else:\n",
    "            print movie_dict.get('Error'), title, year, imdbID\n",
    "            return(pd.Series(['', \n",
    "                              0, 0, 0, 0, 0,\n",
    "                              '', [''], [''], ['']],\n",
    "                             index=['imdb_id', \n",
    "                                    'imdb_rating', 'imdb_votes', \n",
    "                                    'metascore', 'runtime', 'year',\n",
    "                                    'MPAA_rating', 'imdb_genres', \n",
    "                                    'director', 'actors']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "movies_df_subset_1 = pd.concat([movies_df.iloc[0:3000], \n",
    "                                movies_df[['title', 'imdbId']].iloc[0:3000].apply(movie_metadata_extract, axis = 1)],\n",
    "                               axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df_subset_2 = pd.concat([movies_df.iloc[3000:6000], \n",
    "                                movies_df[['title', 'imdbId']].iloc[3000:6000].apply(movie_metadata_extract, axis = 1)],\n",
    "                               axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df_subset_3 = pd.concat([movies_df.iloc[6000:9000], \n",
    "                                movies_df[['title', 'imdbId']].iloc[6000:9000].apply(movie_metadata_extract, axis = 1)],\n",
    "                               axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df_subset_4 = pd.concat([movies_df.iloc[9000:12000], \n",
    "                                movies_df[['title', 'imdbId']].iloc[9000:12000].apply(movie_metadata_extract, axis = 1)],\n",
    "                               axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df_subset_5 = pd.concat([movies_df.iloc[12000:15000], \n",
    "                                movies_df[['title', 'imdbId']].iloc[12000:15000].apply(movie_metadata_extract, axis = 1)],\n",
    "                               axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df_subset_6 = pd.concat([movies_df.iloc[15000:18000], \n",
    "                                movies_df[['title', 'imdbId']].iloc[15000:18000].apply(movie_metadata_extract, axis = 1)],\n",
    "                               axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df_subset_7 = pd.concat([movies_df.iloc[18000:21000], \n",
    "                                movies_df[['title', 'imdbId']].iloc[18000:21000].apply(movie_metadata_extract, axis = 1)],\n",
    "                               axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df_subset_8 = pd.concat([movies_df.iloc[21000:24000], \n",
    "                                movies_df[['title', 'imdbId']].iloc[21000:24000].apply(movie_metadata_extract, axis = 1)],\n",
    "                               axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df_subset_9 = pd.concat([movies_df.iloc[24000:], \n",
    "                                movies_df[['title', 'imdbId']].iloc[24000:].apply(movie_metadata_extract, axis = 1)],\n",
    "                               axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect metadata\n",
    "movies_df_2 = pd.concat([movies_df_subset_1, movies_df_subset_2, movies_df_subset_3, \n",
    "                         movies_df_subset_4, movies_df_subset_5, movies_df_subset_6, \n",
    "                         movies_df_subset_7, movies_df_subset_8, movies_df_subset_9],\n",
    "                        axis = 0)\n",
    "movies_df_2.drop(['imdbId'], axis = 1, inplace = True)\n",
    "\n",
    "movies_df_2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df_2.genres = movies_df_2.genres.apply(lambda x: x.replace('|', ', '))\n",
    "movies_df_2.imdb_genres = movies_df_2.imdb_genres.apply(', '.join)\n",
    "movies_df_2.director = movies_df_2.director.apply(', '.join)\n",
    "movies_df_2.actors = movies_df_2.actors.apply(', '.join)\n",
    "movies_df_2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_metadata = sqlContext.createDataFrame(movies_df_2)\n",
    "del movies_df_2\n",
    "# write movies metadata to parquet file\n",
    "movies_metadata.write.format('parquet').mode('overwrite').save(data_path + 'movie_20m_metadata_original')\n",
    "del movies_metadata\n",
    "# Read parquet: movies_metadata = sqlContext.read.parquet(data_path + 'movie_20m_metadata_original')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
