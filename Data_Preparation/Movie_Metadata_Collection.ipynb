{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDb Movie Metadata Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialization\n",
    "import os\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "\n",
    "# spark imports\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# data science imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path for loading and saving data\n",
    "data_path = 'hdfs:///user/andrew/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import and collect movies data\n",
    "This includes the movieId, title, and genres provided in the Movie Lens data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>[Animation, Children's, Comedy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>[Adventure, Children's, Fantasy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>[Comedy, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>[Comedy, Drama]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>[Comedy]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                             genres  \n",
       "0   [Animation, Children's, Comedy]  \n",
       "1  [Adventure, Children's, Fantasy]  \n",
       "2                 [Comedy, Romance]  \n",
       "3                   [Comedy, Drama]  \n",
       "4                          [Comedy]  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in data through spark since the data is sored in hadoop and format the columns\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SQLContext, Row\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "Item = Row('item_id', 'title' ,'genres')\n",
    "\n",
    "movies = sc.textFile(data_path + 'movies.dat') \\\n",
    "    .map(lambda line: line.split(\"::\")[0:3]) \\\n",
    "    .map(lambda line: (int(line[0]), line[1], line[2].split('|'))) \\\n",
    "    .map(lambda r: Item(*r))\n",
    "movies = sqlContext.createDataFrame(movies)\n",
    "\n",
    "# Collect the data in a simple pandas data frame for easier manipulation\n",
    "movies_df = movies.toPandas()\n",
    "movies_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the OMDb API to collect more movie information\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "# Needed for string conversion\n",
    "import ast\n",
    "import unicodedata\n",
    "\n",
    "def movie_metadata_extract(title_val, api_key = ''):\n",
    "    time.sleep(2)\n",
    "    # remove the year from the title\n",
    "    title = title_val[0:-7]\n",
    "    title = title.split(' (')[0]\n",
    "    if title[-5:] == ', The':\n",
    "        title = 'The ' + title[0:-5]\n",
    "    elif title[-4:] == ', An':\n",
    "        title = 'An ' + title[0:-4]\n",
    "    elif title[-4:] == ', La':\n",
    "        title = 'La ' + title[0:-4]\n",
    "    elif title[-3:] == ', A':\n",
    "        title = 'A ' + title[0:-3]\n",
    "\n",
    "    year = title_val[-5:-1]\n",
    "\n",
    "    # request movie information and parse\n",
    "    movie_request = requests.get('http://www.omdbapi.com/?apikey=' + api_key, \n",
    "                               {'t': title, 'y': year})\n",
    "    movie_dict = ast.literal_eval(movie_request.text.encode('utf-8'))\n",
    "    # when movie metadata is found in OMDb just based on name and year\n",
    "    if movie_dict.get('Response') == 'True':\n",
    "        # extract numeric features\n",
    "        imdb_rating = [0 if movie_dict.get('imdbRating') == 'N/A' \n",
    "                       else float(movie_dict.get('imdbRating'))][0]\n",
    "\n",
    "        imdb_votes = [0 if movie_dict.get('imdbVotes') == 'N/A' \n",
    "                     else int(movie_dict.get('imdbVotes').replace(',', ''))][0]\n",
    "\n",
    "        metascore = [0 if movie_dict.get('Metascore') == 'N/A' \n",
    "                     else int(movie_dict.get('Metascore'))][0]\n",
    "\n",
    "        runtime = [0 if movie_dict.get('Runtime') == 'N/A' \n",
    "                     else int(movie_dict.get('Runtime')[0:-4])][0] \n",
    "        # extract text features\n",
    "        # normalize with decode and encode is because there are many names \n",
    "        # with non ascii standard characters, such as accents, etc\n",
    "        # split genres, directors, and actors into lists\n",
    "        # some names had parenthesis at the end, not sure why, but they are removed. (might be nicknames?)\n",
    "        genre_list = [unicodedata.normalize('NFKD', g.decode('utf-8')).encode('ascii', 'ignore') \n",
    "                      for g in movie_dict.get('Genre').split(', ')]\n",
    "        director_list = [unicodedata.normalize('NFKD', d.decode('utf-8')).encode('ascii', 'ignore') \n",
    "                         for d in movie_dict.get('Director').split(', ')]\n",
    "        director_list = [director.split('(')[0] for director in director_list]\n",
    "        actor_list = [unicodedata.normalize('NFKD', a.decode('utf-8')).encode('ascii', 'ignore') \n",
    "                      for a in movie_dict.get('Actors').split(', ')]\n",
    "        actor_list = [actor.split('(')[0] for actor in actor_list]\n",
    "        # specify column return order\n",
    "        return(pd.Series([movie_dict.get('imdbID'), \n",
    "                          imdb_rating,\n",
    "                          imdb_votes,\n",
    "                          metascore,\n",
    "                          runtime,\n",
    "                          movie_dict.get('Rated'), \n",
    "                          genre_list,\n",
    "                          director_list,\n",
    "                          actor_list],\n",
    "                         index=['imdb_id', \n",
    "                                'imdb_rating', 'imdb_votes', \n",
    "                                'metascore', 'runtime', \n",
    "                                'MPAA_rating', 'imdb_genres', \n",
    "                                'director', 'actors']))\n",
    "    # when movie metadata is not found in OMDb by name and year\n",
    "    # must find IMDb id instead, and then collect from OMDb\n",
    "    else:\n",
    "        # screape IMDb id from google search list\n",
    "        text = title + ' ' + year + ' movie'\n",
    "        text = text.replace(' ', '%20')\n",
    "\n",
    "        response = requests.get('https://google.com/search?q=' + text)\n",
    "\n",
    "        imdbID = ''\n",
    "        soup = BeautifulSoup(response.text)\n",
    "        for a in soup.find_all('a'):\n",
    "              if a.get('href')[0:34] == '/url?q=https://www.imdb.com/title/':\n",
    "                imdbID = a.get('href')[32:45].split('/')[1]\n",
    "                break\n",
    "        \n",
    "        # request movie information and parse\n",
    "        movie_request = requests.get('http://www.omdbapi.com/?apikey=' + api_key, \n",
    "                                     {'i': imdbID})\n",
    "        movie_dict = ast.literal_eval(movie_request.text.encode('utf-8'))\n",
    "        # when movie metadata is found in OMDb using IMDb id\n",
    "        if movie_dict.get('Response') == 'True':\n",
    "            imdb_rating = [0 if movie_dict.get('imdbRating') == 'N/A' \n",
    "                           else float(movie_dict.get('imdbRating'))][0]\n",
    "\n",
    "            imdb_votes = [0 if movie_dict.get('imdbVotes') == 'N/A' \n",
    "                         else int(movie_dict.get('imdbVotes').replace(',', ''))][0]\n",
    "\n",
    "            metascore = [0 if movie_dict.get('Metascore') == 'N/A' \n",
    "                         else int(movie_dict.get('Metascore'))][0]\n",
    "\n",
    "            runtime = [0 if movie_dict.get('Runtime') == 'N/A' \n",
    "                         else int(movie_dict.get('Runtime')[0:-4])][0] \n",
    "            \n",
    "            genre_list = [unicodedata.normalize('NFKD', g.decode('utf-8')).encode('ascii', 'ignore') \n",
    "                          for g in movie_dict.get('Genre').split(', ')]\n",
    "            director_list = [unicodedata.normalize('NFKD', d.decode('utf-8')).encode('ascii', 'ignore') \n",
    "                             for d in movie_dict.get('Director').split(', ')]\n",
    "            director_list = [director.split('(')[0] for director in director_list]\n",
    "            actor_list = [unicodedata.normalize('NFKD', a.decode('utf-8')).encode('ascii', 'ignore') \n",
    "                          for a in movie_dict.get('Actors').split(', ')]\n",
    "            actor_list = [actor.split('(')[0] for actor in actor_list]\n",
    "\n",
    "            return(pd.Series([movie_dict.get('imdbID'), \n",
    "                              imdb_rating,\n",
    "                              imdb_votes,\n",
    "                              metascore,\n",
    "                              runtime,\n",
    "                              movie_dict.get('Rated'), \n",
    "                              genre_list,\n",
    "                              director_list,\n",
    "                              actor_list],\n",
    "                             index=['imdb_id', \n",
    "                                    'imdb_rating', 'imdb_votes', \n",
    "                                    'metascore', 'runtime', \n",
    "                                    'MPAA_rating', 'imdb_genres', \n",
    "                                    'director', 'actors']))\n",
    "        \n",
    "        # when movie metadata is not found in OMDb\n",
    "        else:\n",
    "            # return blank values\n",
    "            print(movie_dict.get('Error') + ' ' + title)\n",
    "            return(pd.Series(['', \n",
    "                              0, 0, 0, 0,\n",
    "                              '', [''], [''], ['']],\n",
    "                             index=['imdb_id', \n",
    "                                    'imdb_rating', 'imdb_votes', \n",
    "                                    'metascore', 'runtime', \n",
    "                                    'MPAA_rating', 'imdb_genres', \n",
    "                                    'director', 'actors']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect metadata\n",
    "movies_df_2 = pd.concat([movies_df, \n",
    "                         movies_df['title'].apply(movie_metadata_extract)],\n",
    "                        axis = 1)\n",
    "# separate the year from the title\n",
    "movies_df_2['year'] = [y[-5:-1] for y in movies_df_2.title]\n",
    "# remove the year from the title\n",
    "movies_df_2['title'] = [t[:-7] for t in movies_df_2.title]\n",
    "\n",
    "movies_df_2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode the genres using the sklearn MultiLabelBinarizer\n",
    "# this works better than pandas get_dummies because it can handle multiple class inputs as lists\n",
    "mlb_movie_lens_genres = MultiLabelBinarizer()\n",
    "movies_df_3 = movies_df_2.join(pd.DataFrame(mlb_movie_lens_genres.fit_transform(movies_df_2.genres),\n",
    "                                            columns = mlb_movie_lens_genres.classes_,\n",
    "                                            index = movies_df_2.index).add_prefix('ml_genre_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb_imdb_genres = MultiLabelBinarizer()\n",
    "movies_df_3 = movies_df_3.join(pd.DataFrame(mlb_imdb_genres.fit_transform(movies_df_3.imdb_genres),\n",
    "                                            columns = mlb_imdb_genres.classes_,\n",
    "                                            index = movies_df_3.index).add_prefix('imdb_genre_')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb_imdb_director = MultiLabelBinarizer()\n",
    "movies_df_3 = movies_df_3.join(pd.DataFrame(mlb_imdb_director.fit_transform(movies_df_3.director),\n",
    "                                            columns = mlb_imdb_director.classes_,\n",
    "                                            index = movies_df_3.index).add_prefix('director_')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb_imdb_actors = MultiLabelBinarizer()\n",
    "movies_df_3 = movies_df_3.join(pd.DataFrame(mlb_imdb_actors.fit_transform(movies_df_3.actors),\n",
    "                                            columns = mlb_imdb_actors.classes_,\n",
    "                                            index = movies_df_3.index).add_prefix('actor_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode MPAA ratings\n",
    "ohe_mpaa_ratings = pd.get_dummies(movies_df_3.MPAA_rating, prefix = 'MPAA_rating')\n",
    "movies_df_3 = pd.concat([movies_df_3, ohe_mpaa_ratings], axis = 1, sort = False)\n",
    "# remove original columns which have been one-hot encoded\n",
    "movies_df_3.drop(['genres', 'imdb_genres', 'director', 'actors', 'MPAA_rating'], axis = 1, inplace = True)\n",
    "# replace spaces with underscored and remove punctuation\n",
    "movies_df_3.columns = [c.replace(' ', '_') for c in movies_df_3.columns]\n",
    "movies_df_3.columns = [c.replace('/', '') for c in movies_df_3.columns]\n",
    "movies_df_3.columns = [c.replace('.', '') for c in movies_df_3.columns]\n",
    "movies_df_3.columns = [c.replace('-', '') for c in movies_df_3.columns]\n",
    "movies_df_3.columns = [c.replace(\"'\", '') for c in movies_df_3.columns]\n",
    "# make sure all titles are ascii standard\n",
    "movies_df_3.title = [unicodedata.normalize('NFKD', t).encode('ascii', 'ignore') \n",
    "                     for t in movies_df_3.title]\n",
    "movies_df_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df_3['item_id'] = movies_df_3.item_id.astype(int)\n",
    "movies_df_3['title'] = movies_df_3.title.astype(str)\n",
    "movies_df_3['imdb_id'] = movies_df_3.imdb_id.astype(str)\n",
    "movies_df_3['imdb_rating'] = movies_df_3.imdb_rating.astype(float)\n",
    "movies_df_3.iloc[:, 4:] = movies_df_3.iloc[:, 4:].astype(int)\n",
    "# Combine MPAA NOT RATED, Not Rated, Unrated, and UNRATED\n",
    "movies_df_3['MPAA_rating_Unrated'] = movies_df_3[[\n",
    "    'MPAA_rating_Unrated', 'MPAA_rating_UNRATED', 'MPAA_rating_NOT_RATED', \n",
    "    'MPAA_rating_Not_Rated']].apply(sum, axis = 1)\n",
    "# Combine APPROVED, Approved, blank, NA, Passed, PASSED\n",
    "movies_df_3['MPAA_rating_Other'] = movies_df_3[[\n",
    "    'MPAA_rating_APPROVED', 'MPAA_rating_Approved', 'MPAA_rating_', \n",
    "    'MPAA_rating_NA', 'MPAA_rating_Passed', 'MPAA_rating_PASSED']].apply(sum, axis = 1)\n",
    "# Combine M, GP, MPG, and PG - These are all the same, just a how the ratings evolved\n",
    "movies_df_3['MPAA_rating_PG'] = movies_df_3[[\n",
    "    'MPAA_rating_PG', 'MPAA_rating_GP', 'MPAA_rating_M', \n",
    "    'MPAA_rating_MPG']].apply(sum, axis = 1)\n",
    "# Drop now unnecessary columns\n",
    "movies_df_3.drop(['MPAA_rating_UNRATED', 'MPAA_rating_NOT_RATED', 'MPAA_rating_APPROVED', \n",
    "                  'MPAA_rating_Approved', 'MPAA_rating_', 'MPAA_rating_NA', \n",
    "                  'MPAA_rating_Passed', 'MPAA_rating_PASSED', 'MPAA_rating_Not_Rated', \n",
    "                  'MPAA_rating_GP', 'MPAA_rating_M', 'MPAA_rating_MPG'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to spark dataframe\n",
    "movies_metadata_OHE = sqlContext.createDataFrame(movies_df_3)\n",
    "# Write movies metadata binarized to parquet file\n",
    "movies_metadata_OHE.write.format('parquet').mode('overwrite').save(data_save_path + 'movie_metadata_OHE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stringify list fields. this simplifies saving, and this can be used as the back up for the OHE dataset\n",
    "movies_df_2.genres = movies_df_2.genres.apply(', '.join)\n",
    "movies_df_2.imdb_genres = movies_df_2.imdb_genres.apply(', '.join)\n",
    "movies_df_2.director = movies_df_2.director.apply(', '.join)\n",
    "movies_df_2.actors = movies_df_2.actors.apply(', '.join)\n",
    "movies_df_2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to spark dataframe\n",
    "movies_metadata = sqlContext.createDataFrame(movies_df_2)\n",
    "# Write movies metadata to parquet file\n",
    "movies_metadata.write.format('parquet').mode('overwrite').save(data_save_path + 'movie_metadata_original')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
