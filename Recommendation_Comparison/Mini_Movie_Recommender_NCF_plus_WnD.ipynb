{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some functions are from or based on work done by Kevin Liao in the below notebook\n",
    "# https://github.com/KevinLiao159/MyDataSciencePortfolio/blob/master/movie_recommender/movie_recommendation_using_ALS.ipynb\n",
    "\n",
    "# Intialization\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import datetime as df\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "\n",
    "# spark imports\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import UserDefinedFunction, explode, desc\n",
    "from pyspark.sql.types import StringType, ArrayType\n",
    "from zoo.models.recommendation import *\n",
    "from zoo.models.recommendation.utils import *\n",
    "from zoo.common.nncontext import init_nncontext\n",
    "\n",
    "from bigdl.dataset.transformer import *\n",
    "from bigdl.dataset.base import *\n",
    "from bigdl.nn.criterion import *\n",
    "from bigdl.optim.optimizer import *\n",
    "from bigdl.util.common import *\n",
    "from bigdl.nn.layer import *\n",
    "\n",
    "# data science imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "init_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'hdfs:///user/andrew/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 404 ms, sys: 41.3 ms, total: 445 ms\n",
      "Wall time: 10.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Read in data through spark since the data is sored in hadoop and format the columns\n",
    "# Convert to pandas dataframes for easier and faster manipulation\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SQLContext, Row\n",
    "from pyspark.sql.functions import *\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "\n",
    "movies = sqlContext.read.parquet(data_path + 'movie_metadata_OHE_subset')\n",
    "movies_df = movies.toPandas()\n",
    "movies_df = movies_df.set_index(movies_df.item_id) # set index so no sorting errors occur\n",
    "\n",
    "# movies_gp = sqlContext.read.parquet('hdfs:///user/andrew/movie_genre_and_people_metadata_ohe_subset')\n",
    "movies_gp = movies.drop('title', 'imdb_id', 'imdb_rating', 'imdb_votes', 'metascore', 'runtime', 'year')\n",
    "\n",
    "users_full_sdf = sqlContext.read.parquet(data_path + 'users_metadata') \n",
    "users_full_sdf = users_full_sdf.na.fill(0)\n",
    "\n",
    "Rating = Row(\"userId\", \"itemId\", \"label\") # Ignore timestamp\n",
    "ratings = sc.textFile(data_path + 'ratings.dat')\\\n",
    "    .map(lambda line: line.split(\"::\")[0:3])\\\n",
    "    .map(lambda line: map(int, line))\\\n",
    "    .map(lambda r: Rating(*r))\n",
    "ratings = sqlContext.createDataFrame(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User input function - takes user input data, strpis it down, and calls other functions on that data\n",
    "# Takes in user age, gender, list of favorite movies\n",
    "# All movies in the list of favorite movies will be rated 5 stars\n",
    "def new_user_input(fav_movies, all_ratings, movies, spark_context, \n",
    "                   sqlContext = None, num_recs = 10, age = None, \n",
    "                   gender = None, movies_gp = None, movies_df = None):\n",
    "    # age should be an integer in 1 - 100\n",
    "    # gender should be M or F\n",
    "    # fav_movies should be in the form of [\"Iron Man\", \"The Shawshank Redemption\", \"Robin Hood\"]\n",
    "    #    If there are multiple versions of the movie and the user wishes for one other than the most recent one, they\n",
    "    #    should specify with a year in parenthesis, like \"Robin Hood (1993)\"\n",
    "    \n",
    "    # Collect favorite movie ids\n",
    "    print 'Collecting favorite movie IDs'\n",
    "    movieIds = get_movieId(movies_df, fav_movies)\n",
    "    print 'Favorite movies in the available set'\n",
    "    print movies_df[['item_id', 'title', 'year']].loc[movieIds]\n",
    "    \n",
    "    print 'Adding ratings to full set'\n",
    "    # Add new user movie ratings to all ratings dataframe\n",
    "    all_ratings_updated, new_user_ratings = add_new_user_to_data(all_ratings, movieIds, spark_context)\n",
    "    del all_ratings\n",
    "    \n",
    "    print 'Creating prediction set'\n",
    "    all_user_unrated = get_inference_data(all_ratings_updated, movieIds)\n",
    "    \n",
    "    print 'Formatting training and prediction dataframes for NCF'\n",
    "    # Format ratings data into RDD Samples (the format needed for Analytics Zoo models)\n",
    "    trainPairFeatureRdds = all_ratings_updated.rdd.map(lambda x: build_sample(x[0], x[1], x[2]))\n",
    "    predPairFeatureRdds = all_user_unrated.rdd.map(lambda x: build_sample(x[0], x[1], x[2]))\n",
    "\n",
    "    train_rdd = trainPairFeatureRdds.map(lambda pair_feature: pair_feature.sample)\n",
    "    pred_rdd = predPairFeatureRdds.map(lambda pair_feature: pair_feature.sample)\n",
    "    \n",
    "    print 'Training NCF Model'\n",
    "    # Train NCF model, then recommend new movies    \n",
    "    batch_size = 46080\n",
    "    max_user_id = all_ratings_updated.agg({'userId': 'max'}).collect()[0]['max(userId)']\n",
    "    max_movie_id = all_ratings_updated.agg({'itemId': 'max'}).collect()[0]['max(itemId)']\n",
    "\n",
    "    ncf = NeuralCF(user_count = max_user_id, item_count = max_movie_id, \n",
    "                   class_num = 5, hidden_layers = [20, 10], include_mf = False)\n",
    "\n",
    "    optimizer = Optimizer(\n",
    "        model=ncf,\n",
    "        training_rdd=train_rdd,\n",
    "        criterion=ClassNLLCriterion(),\n",
    "        end_trigger=MaxEpoch(10),\n",
    "        batch_size=batch_size,\n",
    "        optim_method=Adam(learningrate=0.001))\n",
    "\n",
    "    optimizer.optimize()\n",
    "    # del all_ratings_updated\n",
    "    \n",
    "    print 'Making Predictions'\n",
    "    # Determine top 3*num_recs recommendations\n",
    "    full_predictions_sorted = ncf.recommend_for_user(predPairFeatureRdds, 3*num_recs).toDF().sort(desc('prediction'))\n",
    "    # Keep only num_recs from the sorted set for the recommendations\n",
    "    ncf_top_n_predictions = full_predictions_sorted.take(num_recs)\n",
    "    # Extract movie ids\n",
    "    ncf_top_n_ids = [r[1] for r in ncf_top_n_predictions]\n",
    "    \n",
    "    ncf_movie_recs = movies.filter(movies.item_id.isin(ncf_top_n_ids)).select('title', 'year')\n",
    "    print ''\n",
    "    print 'NCF Recommendations'\n",
    "    print ncf_movie_recs.toPandas()\n",
    "    \n",
    "    \n",
    "    # Import WnD model input data format\n",
    "    # Create user_id x item_id matrix need to get data in the form of user_id, item_id, label, then pivot\n",
    "    # filter movies_gp dataframe by the movieIds. Pivot new_user_ratings into a vector, \n",
    "    # then multiply by the filtered movies_gp dataframe; divide by binarized user ratings; \n",
    "    # this should now be a vector of user preferences. \n",
    "    # Join a OHE age, gender, and possibly occupation, to the user preferences\n",
    "    user_summary_sdf = get_user_preferences(user_ratings = new_user_ratings, movieIds = movieIds, \n",
    "                                            movies_gp = movies_gp, age = 26, gender = 'M', \n",
    "                                            sqlContext = sqlContext)\n",
    "\n",
    "    ncf_top_3xn_ids = full_predictions_sorted.select('item_id')\n",
    "    all_user_unrated_top_3xn = all_user_unrated.join(ncf_top_3xn_ids, all_user_unrated.itemId == ncf_top_3xn_ids.item_id, \n",
    "                                                     'inner').drop(ncf_top_3xn_ids.item_id)\n",
    "    top_3xn_movies_metadata = movies.join(ncf_top_3xn_ids, movies.item_id == ncf_top_3xn_ids.item_id, \n",
    "                                          'inner').drop(ncf_top_3xn_ids.item_id)\n",
    "        \n",
    "    # lastly, replicate the user pref rows for each rated movieId, then join with the filtered movies dataframe\n",
    "    # (MAKE SURE ALL COLUMNS ARE ORDERED AND NAMED CORRECTLY)\n",
    "    unrated_with_movie_metadata = all_user_unrated_top_3xn \\\n",
    "                                    .join(top_3xn_movies_metadata, \n",
    "                                          all_user_unrated_top_3xn.itemId == top_3xn_movies_metadata.item_id, \n",
    "                                          how = 'left') \\\n",
    "                                    .drop(top_3xn_movies_metadata.item_id)\n",
    "    unrated_with_full_metadata = unrated_with_movie_metadata \\\n",
    "                                    .join(user_summary_sdf, on = 'userId', how = 'left')\n",
    "    # Create lists of columns sets\n",
    "    identifier_fields = ['userId', 'itemId', 'label', 'title', 'imdb_id']\n",
    "    continuous_base_fields = ['imdb_rating', 'imdb_votes', 'metascore', 'runtime', 'year']\n",
    "    indicator_base_fields = ['gender_F', 'gender_M', 'age_group_1', \n",
    "                             'age_group_18', 'age_group_25', 'age_group_35', \n",
    "                             'age_group_45', 'age_group_50', 'age_group_56']\n",
    "    all_base_fields = identifier_fields + continuous_base_fields + indicator_base_fields\n",
    "\n",
    "    user_avgs = [col_name for col_name in unrated_with_full_metadata.columns if col_name[-11:] == '_avg_rating']\n",
    "    movie_metadata = [col_name for col_name in unrated_with_full_metadata.columns \n",
    "                      if (col_name[-11:] != '_avg_rating' and col_name not in all_base_fields)]\n",
    "\n",
    "    user_avgs_genres = [genre for genre in user_avgs if 'genre' in genre]\n",
    "    user_avgs_ml_genres = [genre for genre in user_avgs if genre[:8] == 'ml_genre']\n",
    "    user_avgs_imdb_genres = [genre for genre in user_avgs if genre[:10] == 'imdb_genre']\n",
    "    user_avgs_directors = [director for director in user_avgs if director[0:9] == 'director_']\n",
    "    user_avgs_actors = [actor for actor in user_avgs if actor[0:6] == 'actor_']\n",
    "\n",
    "    movie_genres = [genre for genre in movie_metadata if 'genre' in genre]\n",
    "    movie_ml_genres = [genre for genre in movie_metadata if genre[:8] == 'ml_genre']\n",
    "    movie_imdb_genres = [genre for genre in movie_metadata if genre[:10] == 'imdb_genre']\n",
    "    movie_directors = [director for director in movie_metadata if director[0:9] == 'director_']\n",
    "    movie_actors = [actor for actor in movie_metadata if actor[0:6] == 'actor_']\n",
    "    \n",
    "    # Determine embedding dimmensions\n",
    "    max_user_id = unrated_with_full_metadata.agg({\"userId\": \"max\"}).collect()[0][0]\n",
    "    max_movie_id = unrated_with_full_metadata.agg({\"itemId\": \"max\"}).collect()[0][0]\n",
    "    # num_rating_labels = unrated_with_full_metadata.select('label').distinct().count() - This is already part of the model\n",
    "    \n",
    "    # Specify column sets to be used for different parts of the Wide&Deep model\n",
    "    # Column dims values need to be greater than the dims of the columns. \n",
    "    # For indicator columns the dim is 3 because the column has two levels, \n",
    "    # and for avgs the dim is 6 because the column has values up to 5\n",
    "    # bucket_size = 100\n",
    "    wide_base_cols = indicator_base_fields + movie_genres + user_avgs_genres\n",
    "    wide_base_dims = [3 for i in (indicator_base_fields + movie_genres)] + [6 for i in user_avgs_genres]\n",
    "    indicator_cols = indicator_base_fields + movie_genres\n",
    "    indicator_dims = [3 for i in indicator_cols]\n",
    "    continuous_cols = continuous_base_fields + user_avgs_genres\n",
    "    column_info = ColumnFeatureInfo(\n",
    "                wide_base_cols = wide_base_cols,\n",
    "                wide_base_dims = wide_base_dims,\n",
    "                # wide_cross_cols = [\"age-gender\"],\n",
    "                # wide_cross_dims = [bucket_size],\n",
    "                indicator_cols = indicator_cols,\n",
    "                indicator_dims = indicator_dims,\n",
    "                embed_cols = [\"userId\", \"itemId\"],\n",
    "                embed_in_dims = [max_user_id, max_movie_id],\n",
    "                embed_out_dims = [100, 100],\n",
    "                continuous_cols = continuous_cols)\n",
    "    \n",
    "    # Format coumns to feature\n",
    "    wnd_pred_rdd = unrated_with_full_metadata.rdd.map(lambda row: to_user_item_feature(row, column_info))\n",
    "    \n",
    "    # Import the WideAndDeep model\n",
    "    WnDModel = WideAndDeep.load_model(path = data_path + 'WnD_Model.bigdl', \n",
    "                                      weight_path = data_path + 'WnD_Model_weights.h5')\n",
    "    \n",
    "    # Recommend items for the new user\n",
    "    wnd_user_recs = WnDModel.recommend_for_user(wnd_pred_rdd, num_recs)\n",
    "    # Extract the item_ids for the recommended items\n",
    "    user_recs = [user_rec.item_id for user_rec in wnd_user_recs.take(num_recs)]\n",
    "\n",
    "    # Filter the movies sdf for only the recommended items\n",
    "    wnd_movie_recs = movies.filter(col('item_id').isin(user_recs)).select('title', 'year')\n",
    "    print ' '\n",
    "    print 'Wind&Deep Recommendations'\n",
    "    print wnd_movie_recs.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movieId(movies_df, fav_movie_list):\n",
    "    \"\"\"\n",
    "    return all movieId(s) of user's favorite movies\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_movies: spark Dataframe, movies data\n",
    "    \n",
    "    fav_movie_list: list, user's list of favorite movies\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    movieId_list: list of movieId(s)\n",
    "    \"\"\"\n",
    "    movieId_list = []\n",
    "    for movie in fav_movie_list:\n",
    "        # Remove first word in specific cases. This is because sometimes the first word is listed \n",
    "        # at the end of the movie title and would not be found by the search if it is included.\n",
    "        if movie[0:4] == 'The ':\n",
    "            movie = movie[4:]\n",
    "        elif movie[0:3] == 'An ':\n",
    "            movie = movie[3:]\n",
    "        elif movie[0:3] == 'La ':\n",
    "            movie = movie[3:]\n",
    "        elif movie[0:2] == 'A ':\n",
    "            movie = movie[3:]\n",
    "        \n",
    "        # If a year is provided by the user, remove it from the title and use it in the filtering.\n",
    "        if movie[-6:-5] == '(':\n",
    "            year = int(movie[-5:-1])\n",
    "            movie = movie[0:-7]\n",
    "            movieIds = movies_df.item_id[(movies_df.title.str.contains(movie)) & (movies_df.year == year)]\n",
    "            movieId_list.extend(movieIds)\n",
    "        # If no year is provided, determine if the title is a single word.\n",
    "        # If it is a single work, find an exact match\n",
    "        elif len(movie.split(' ')) == 1:\n",
    "            movieIds = movies_df.item_id[movies_df.title == movie]\n",
    "            movieId_list.extend(movieIds)\n",
    "        # Otherwise search for the movie title\n",
    "        else:\n",
    "            movieIds = movies_df.item_id[movies_df.title.str.contains(movie)]\n",
    "            movieId_list.extend(movieIds)\n",
    "    return movieId_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_user_to_data(train_data, movieIds, spark_context):\n",
    "    \"\"\"\n",
    "    add new rows with new user, user's movie and ratings to\n",
    "    existing train data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_data: Spark DataFrame, ratings data\n",
    "    \n",
    "    movieIds: spark DataFrame, single column of movieId(s)\n",
    "\n",
    "    spark_context: Spark Context object\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    new train data with the new user's rows\n",
    "    \"\"\"\n",
    "    # Get new user id\n",
    "    new_id = train_data.agg({\"userId\": \"max\"}).collect()[0][0] + 1\n",
    "    # Get max rating\n",
    "    max_rating = train_data.agg({\"label\": \"max\"}).collect()[0][0]\n",
    "    # Create new user sdf for max rating\n",
    "    user_rows_max = [(new_id, movieId, max_rating) for movieId in movieIds]\n",
    "    new_sdf_max = spark_context.parallelize(user_rows_max).toDF(['userId', 'itemId', 'label'])\n",
    "    # Return new train data\n",
    "    return train_data.union(new_sdf_max), new_sdf_max # , new_sdf_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inference_data(train_data, movieIds):\n",
    "    \"\"\"\n",
    "    return a rdd with the userid and all movies (except ones in movieId_list)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_data: spark RDD, ratings data\n",
    "\n",
    "    df_movies: spark Dataframe, movies data\n",
    "    \n",
    "    movieId_list: list, list of movieId(s)\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    inference data: Spark RDD\n",
    "    \"\"\"\n",
    "    # Get new user id\n",
    "    new_id = train_data.agg({\"userId\": \"max\"}).collect()[0][0]\n",
    "    # Get the set of movies that have not been rated by the user\n",
    "    distinct_unrated_items = ratings.select('itemId').distinct().filter(~col('itemId').isin(movieIds))\n",
    "    # Create the dataset for the new user with their unrated movies\n",
    "    user_unrated = distinct_unrated_items.withColumn('userId', lit(new_id)).select('userId', 'itemId')\n",
    "    user_unrated = user_unrated.withColumn('label', lit(0))\n",
    "    return user_unrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sample(user_id, item_id, rating):\n",
    "    sample = Sample.from_ndarray(np.array([user_id, item_id]), np.array([rating]))\n",
    "    return UserItemFeature(user_id, item_id, sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_preferences(user_ratings, movieIds, movies_gp, age, gender, sqlContext):\n",
    "    user_demog = pd.DataFrame({'gender_M': 0, 'gender_F': 0, 'age_group_1': 0, \n",
    "                               'age_group_18': 0, 'age_group_25': 0, 'age_group_35': 0, \n",
    "                               'age_group_45': 0, 'age_group_50': 0, 'age_group_56': 0}, index = [0])\n",
    "    # Bin user by age\n",
    "    if age < 18:\n",
    "        user_demog.age_group_1[0] = 1\n",
    "    elif age < 25:\n",
    "        user_demog.age_group_18[0] = 1\n",
    "    elif age < 35:\n",
    "        user_demog.age_group_25[0] = 1\n",
    "    elif age < 45:\n",
    "        user_demog.age_group_35[0] = 1\n",
    "    elif age < 50:\n",
    "        user_demog.age_group_45[0] = 1\n",
    "    elif age < 56:\n",
    "        user_demog.age_group_50[0] = 1\n",
    "    else:\n",
    "        user_demog.age_group_56[0] = 1\n",
    "    # Binarize gender\n",
    "    if gender == 'M':\n",
    "        user_demog.gender_M[0] = 1\n",
    "    else:\n",
    "        user_demog.gender_F[0] = 1\n",
    "        \n",
    "    # new_user_ratings\n",
    "    # Create the user-item matrix for the new user\n",
    "    pivoted_user_ratings_df = user_ratings.toPandas() \\\n",
    "                                            .pivot(index='userId', \n",
    "                                                   columns='itemId',\n",
    "                                                   values='label') \\\n",
    "                                            .fillna(0)\n",
    "    pivoted_user_ratings_df_binary = pivoted_user_ratings_df / pivoted_user_ratings_df\n",
    "    \n",
    "    # Reduce the movie set to only the user's rate movies\n",
    "    movies_gp_filtered = movies_gp.filter(col('item_id').isin(movieIds))\n",
    "    movies_gp_filtered_df = movies_gp_filtered.toPandas()\n",
    "    movies_gp_filtered_df = movies_gp_filtered_df.set_index('item_id')\n",
    "    \n",
    "    # Create user profile\n",
    "    user_summary_total = pivoted_user_ratings_df.dot(movies_gp_filtered_df)\n",
    "    user_summary_count = pivoted_user_ratings_df_binary.dot(movies_gp_filtered_df)\n",
    "    user_summary_avg = (user_summary_total / user_summary_count).fillna(0)\n",
    "    user_summary_avg = user_summary_avg.add_suffix('_avg_rating').reset_index()\n",
    "    \n",
    "    # Create Spark dataframe output for full user profile\n",
    "    user_summary = pd.concat([user_summary_avg, user_demog], axis = 1)\n",
    "    sorted_columns = list(user_summary.columns.sort_values())\n",
    "    user_summary_sdf = sqlContext.createDataFrame(user_summary[sorted_columns])\n",
    "    return user_summary_sdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step by Step Walkthrough of Main Function (to show runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting favorite movie IDs\n",
      "Favorite movies in the available set\n",
      "         item_id                      title  year\n",
      "item_id                                          \n",
      "318          318  Shawshank Redemption, The  1994\n",
      "2116        2116     Lord of the Rings, The  1978\n",
      "CPU times: user 14.4 ms, sys: 4.5 ms, total: 18.9 ms\n",
      "Wall time: 17 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fav_movies = ['Tinker Tailor Soldier Spy', 'Shawshank Redemption', 'Lord of the Rings']\n",
    "# collect favorite movie ids\n",
    "print 'Collecting favorite movie IDs'\n",
    "movieIds = get_movieId(movies_df, fav_movies)\n",
    "if movies_df is not None:\n",
    "    print 'Favorite movies in the available set'\n",
    "    print movies_df[['item_id', 'title', 'year']].loc[movieIds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding ratings to full set\n",
      "CPU times: user 45.5 ms, sys: 5.5 ms, total: 51 ms\n",
      "Wall time: 10.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print 'Adding ratings to full set'\n",
    "# add new user movie ratings to all ratings dataframe\n",
    "all_ratings_updated, user_ratings = add_new_user_to_data(ratings, movieIds, sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating prediction set\n",
      "CPU times: user 14.5 ms, sys: 4.35 ms, total: 18.8 ms\n",
      "Wall time: 4.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print 'Creating prediction set'\n",
    "all_user_unrated = get_inference_data(all_ratings_updated, movieIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatting training and prediction dataframes for NCF\n",
      "CPU times: user 815 µs, sys: 828 µs, total: 1.64 ms\n",
      "Wall time: 102 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print 'Formatting training and prediction dataframes for NCF'\n",
    "# Fornat ratings data into RDD Samples (the format needed for Analytics Zoo models)\n",
    "trainPairFeatureRdds = all_ratings_updated.rdd.map(lambda x: build_sample(x[0], x[1], x[2]))\n",
    "predPairFeatureRdds = all_user_unrated.rdd.map(lambda x: build_sample(x[0], x[1], x[2]))\n",
    "\n",
    "train_rdd = trainPairFeatureRdds.map(lambda pair_feature: pair_feature.sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training NCF Model\n",
      "creating: createZooNeuralCF\n",
      "creating: createClassNLLCriterion\n",
      "creating: createMaxEpoch\n",
      "creating: createAdam\n",
      "creating: createDistriOptimizer\n",
      "CPU times: user 35.3 ms, sys: 11.6 ms, total: 46.9 ms\n",
      "Wall time: 50 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print 'Training NCF Model'\n",
    "# train NCF model, then predict movie ratings    \n",
    "batch_size = 46080\n",
    "max_user_id = all_ratings_updated.agg({'userId': 'max'}).collect()[0]['max(userId)']\n",
    "max_item_id = all_ratings_updated.agg({'itemId': 'max'}).collect()[0]['max(itemId)']\n",
    "\n",
    "ncf = NeuralCF(user_count = max_user_id, item_count = max_item_id, \n",
    "               class_num = 5, hidden_layers = [20, 10], include_mf = False)\n",
    "\n",
    "optimizer = Optimizer(\n",
    "    model=ncf,\n",
    "    training_rdd=train_rdd,\n",
    "    criterion=ClassNLLCriterion(),\n",
    "    end_trigger=MaxEpoch(10),\n",
    "    batch_size=batch_size,\n",
    "    optim_method=Adam(learningrate=0.001))\n",
    "\n",
    "optimizer.optimize()\n",
    "# del all_ratings_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making Predictions\n",
      "\n",
      "NCF Recommendations\n",
      "                                                title  year\n",
      "0                                 Usual Suspects, The  1995\n",
      "1                                            Ridicule  1996\n",
      "2                                 Wrong Trousers, The  1993\n",
      "3                                      Third Man, The  1949\n",
      "4                                     White Christmas  1954\n",
      "5                                    Schindler's List  1993\n",
      "6   Seven Samurai (The Magnificent Seven) (Shichin...  1954\n",
      "7                                           Bluebeard  1944\n",
      "8                                            Rushmore  1998\n",
      "9                                     King and I, The  1956\n",
      "10                                           Trekkies  1997\n",
      "11                                     Close Shave, A  1995\n",
      "12                                            Foxfire  1996\n",
      "13                                     Godfather, The  1972\n",
      "14                                Maltese Falcon, The  1941\n",
      "CPU times: user 64.8 ms, sys: 13.9 ms, total: 78.7 ms\n",
      "Wall time: 9.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print 'Making Predictions'\n",
    "# keep top 15 predictions\n",
    "num_recs = 15\n",
    "full_predictions_sorted = ncf.recommend_for_user(predPairFeatureRdds, 3*num_recs).toDF().sort(desc('prediction'))\n",
    "ncf_top_n_predictions = full_predictions_sorted.take(num_recs)\n",
    "# extract movie ids\n",
    "ncf_top_n_ids = [r[1] for r in ncf_top_n_predictions]\n",
    "\n",
    "ncf_movie_recs = movies.filter(movies.item_id.isin(ncf_top_n_ids)).select('title', 'year')\n",
    "print ''\n",
    "print 'NCF Recommendations'\n",
    "print ncf_movie_recs.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57.4 ms, sys: 10.5 ms, total: 67.9 ms\n",
      "Wall time: 5.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# import WnD model input data format\n",
    "# Create user_id x item_id matrix need to get data in the form of user_id, item_id, label, then pivot\n",
    "# filter movies_gp dataframe by the movieIds. pivot new_user_ratings into a vector, \n",
    "# then multiply by the filtered movies_gp dataframe; divide by binarized user ratings; \n",
    "# this should now be a vector of user preferences. \n",
    "# join a OHE age, gender, and possibly occupation, to the user preferences\n",
    "user_summary_sdf = get_user_preferences(user_ratings = user_ratings, movieIds = movieIds, \n",
    "                                        movies_gp = movies_gp, age = 26, gender = 'M', \n",
    "                                        sqlContext = sqlContext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.61 ms, sys: 0 ns, total: 3.61 ms\n",
      "Wall time: 142 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ncf_top_3xn_ids = full_predictions_sorted.select('item_id')\n",
    "all_user_unrated_top_3xn = all_user_unrated.join(ncf_top_3xn_ids, all_user_unrated.itemId == ncf_top_3xn_ids.item_id, \n",
    "                                                 'inner').drop(ncf_top_3xn_ids.item_id)\n",
    "top_3xn_movies_metadata = movies.join(ncf_top_3xn_ids, movies.item_id == ncf_top_3xn_ids.item_id, \n",
    "                                      'inner').drop(ncf_top_3xn_ids.item_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.4 ms, sys: 1.45 ms, total: 7.85 ms\n",
      "Wall time: 267 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# lastly, replicate the user pref rows for each rated movieId, then join with the filtered movies dataframe\n",
    "# (MAKE SURE ALL COLUMNS ARE ORDERED AND NAMED CORRECTLY)\n",
    "unrated_with_movie_metadata = all_user_unrated_top_3xn \\\n",
    "                                .join(top_3xn_movies_metadata, \n",
    "                                      all_user_unrated_top_3xn.itemId == top_3xn_movies_metadata.item_id, \n",
    "                                      how = 'left') \\\n",
    "                                .drop(top_3xn_movies_metadata.item_id)\n",
    "unrated_with_full_metadata = unrated_with_movie_metadata \\\n",
    "                                .join(user_summary_sdf, on = 'userId', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "identifier_fields = ['userId', 'itemId', 'label', 'title', 'imdb_id']\n",
    "continuous_base_fields = ['imdb_rating', 'imdb_votes', 'metascore', 'runtime', 'year']\n",
    "indicator_base_fields = ['gender_F', 'gender_M', 'age_group_1', \n",
    "                         'age_group_18', 'age_group_25', 'age_group_35', \n",
    "                         'age_group_45', 'age_group_50', 'age_group_56']\n",
    "all_base_fields = identifier_fields + continuous_base_fields + indicator_base_fields\n",
    "\n",
    "user_avgs = [col_name for col_name in unrated_with_full_metadata.columns if col_name[-11:] == '_avg_rating']\n",
    "movie_metadata = [col_name for col_name in unrated_with_full_metadata.columns \n",
    "                  if (col_name[-11:] != '_avg_rating' and col_name not in all_base_fields)]\n",
    "\n",
    "user_avgs_genres = [genre for genre in user_avgs if 'genre' in genre]\n",
    "user_avgs_ml_genres = [genre for genre in user_avgs if genre[:8] == 'ml_genre']\n",
    "user_avgs_imdb_genres = [genre for genre in user_avgs if genre[:10] == 'imdb_genre']\n",
    "user_avgs_directors = [director for director in user_avgs if director[0:9] == 'director_']\n",
    "user_avgs_actors = [actor for actor in user_avgs if actor[0:6] == 'actor_']\n",
    "\n",
    "movie_genres = [genre for genre in movie_metadata if 'genre' in genre]\n",
    "movie_ml_genres = [genre for genre in movie_metadata if genre[:8] == 'ml_genre']\n",
    "movie_imdb_genres = [genre for genre in movie_metadata if genre[:10] == 'imdb_genre']\n",
    "movie_directors = [director for director in movie_metadata if director[0:9] == 'director_']\n",
    "movie_actors = [actor for actor in movie_metadata if actor[0:6] == 'actor_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_user_id = unrated_with_full_metadata.agg({\"userId\": \"max\"}).collect()[0][0]\n",
    "max_movie_id = unrated_with_full_metadata.agg({\"itemId\": \"max\"}).collect()[0][0]\n",
    "num_rating_labels = unrated_with_full_metadata.select('label').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_size = 100\n",
    "wide_base_cols = indicator_base_fields + movie_genres + user_avgs_genres\n",
    "wide_base_dims = [3 for i in (indicator_base_fields + movie_genres)] + [6 for i in user_avgs_genres]\n",
    "indicator_cols = indicator_base_fields + movie_genres\n",
    "indicator_dims = [3 for i in indicator_cols]\n",
    "continuous_cols = continuous_base_fields + user_avgs_genres\n",
    "column_info = ColumnFeatureInfo(\n",
    "            wide_base_cols = wide_base_cols,\n",
    "            wide_base_dims = wide_base_dims,\n",
    "            # wide_cross_cols = [\"age-gender\"],\n",
    "            # wide_cross_dims = [bucket_size],\n",
    "            indicator_cols = indicator_cols,\n",
    "            indicator_dims = indicator_dims,\n",
    "            embed_cols = [\"userId\", \"itemId\"],\n",
    "            embed_in_dims = [max_user_id, max_movie_id],\n",
    "            embed_out_dims = [100, 100],\n",
    "            continuous_cols = continuous_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.31 ms, sys: 3.17 ms, total: 11.5 ms\n",
      "Wall time: 3.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wnd_pred_rdd = unrated_with_full_metadata.rdd.map(lambda row: to_user_item_feature(row, column_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.6 ms, sys: 630 µs, total: 2.23 ms\n",
      "Wall time: 1.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "WnDModel = WideAndDeep.load_model(path = data_path + 'WnD_Model.bigdl', \n",
    "                                  weight_path = data_path + 'WnD_Model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57.4 ms, sys: 16.4 ms, total: 73.8 ms\n",
      "Wall time: 6.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wnd_user_recs = WnDModel.recommend_for_user(wnd_pred_rdd, num_recs)\n",
    "user_recs = [user_rec.item_id for user_rec in wnd_user_recs.take(num_recs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wind&Deep Recommendations\n",
      "                                 title  year\n",
      "0                          Nine Months  1995\n",
      "1        Bridge on the River Kwai, The  1957\n",
      "2      Monty Python and the Holy Grail  1974\n",
      "3                   Lawrence of Arabia  1962\n",
      "4                              Yojimbo  1961\n",
      "5                           Spaceballs  1987\n",
      "6   Star Wars: Episode IV - A New Hope  1977\n",
      "7                      American Beauty  1999\n",
      "8                      King and I, The  1956\n",
      "9                          Matrix, The  1999\n",
      "10                        Jackie Brown  1997\n",
      "11                      Close Shave, A  1995\n",
      "12                      Godfather, The  1972\n",
      "13                        Citizen Kane  1941\n",
      "14                  Driving Miss Daisy  1989\n",
      "CPU times: user 17.4 ms, sys: 2.18 ms, total: 19.5 ms\n",
      "Wall time: 3.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wnd_movie_recs = movies.filter(col('item_id').isin(user_recs)).select('title', 'year')\n",
    "print 'Wind&Deep Recommendations'\n",
    "print wnd_movie_recs.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Function Recommendation Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting favorite movie IDs\n",
      "Favorite movies in the available set\n",
      "         item_id                      title  year\n",
      "item_id                                          \n",
      "318          318  Shawshank Redemption, The  1994\n",
      "2116        2116     Lord of the Rings, The  1978\n",
      "2376        2376          View to a Kill, A  1985\n",
      "Adding ratings to full set\n",
      "Creating prediction set\n",
      "Formatting training and prediction dataframes for NCF\n",
      "Training NCF Model\n",
      "creating: createZooNeuralCF\n",
      "creating: createClassNLLCriterion\n",
      "creating: createMaxEpoch\n",
      "creating: createAdam\n",
      "creating: createDistriOptimizer\n",
      "Making Predictions\n",
      "\n",
      "NCF Recommendations\n",
      "                                               title  year\n",
      "0                                Usual Suspects, The  1995\n",
      "1                                       Verdict, The  1982\n",
      "2                           Rescuers Down Under, The  1990\n",
      "3                                      Forever Young  1992\n",
      "4                                     Meet Joe Black  1998\n",
      "5                                        Matrix, The  1999\n",
      "6  Dr. Strangelove or: How I Learned to Stop Worr...  1963\n",
      "7                                            Matilda  1996\n",
      "8                                         Casablanca  1942\n",
      "9                                       Citizen Kane  1941\n",
      " \n",
      "Wind&Deep Recommendations\n",
      "                             title  year\n",
      "0              Usual Suspects, The  1995\n",
      "1                   Batman Returns  1992\n",
      "2  Monty Python and the Holy Grail  1974\n",
      "3          Raiders of the Lost Ark  1981\n",
      "4          Godfather: Part II, The  1974\n",
      "5                     Verdict, The  1982\n",
      "6                            Fargo  1996\n",
      "7      Back to the Future Part III  1990\n",
      "8                     Pulp Fiction  1994\n",
      "9                       Casablanca  1942\n",
      "CPU times: user 330 ms, sys: 97.6 ms, total: 427 ms\n",
      "Wall time: 1min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fav_movies = ['Iron Man', 'Tinker Tailor Soldier Spy', 'Shawshank Redemption', 'Lord of the Rings', 'Harry Potter',\n",
    "             'The Family Stone', 'Shaun of the Dead', 'Up', 'A View to a Kill']\n",
    "new_user_input(fav_movies = fav_movies, all_ratings = ratings, \n",
    "               movies = movies, spark_context = sc, sqlContext = sqlContext,\n",
    "               num_recs = 10, age = 26, gender = 'M', movies_gp = movies_gp, movies_df = movies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting favorite movie IDs\n",
      "Favorite movies in the available set\n",
      "         item_id                      title  year\n",
      "item_id                                          \n",
      "318          318  Shawshank Redemption, The  1994\n",
      "2116        2116     Lord of the Rings, The  1978\n",
      "Adding ratings to full set\n",
      "Creating prediction set\n",
      "Formatting training and prediction dataframes for NCF\n",
      "Training NCF Model\n",
      "creating: createZooNeuralCF\n",
      "creating: createClassNLLCriterion\n",
      "creating: createMaxEpoch\n",
      "creating: createAdam\n",
      "creating: createDistriOptimizer\n",
      "Making Predictions\n",
      "\n",
      "NCF Recommendations\n",
      "                      title  year\n",
      "0             Cool Runnings  1993\n",
      "1            Paths of Glory  1957\n",
      "2                 Beautiful  2000\n",
      "3               Blue Hawaii  1961\n",
      "4         Cold Comfort Farm  1995\n",
      "5                   Sanjuro  1962\n",
      "6                  Trekkies  1997\n",
      "7  Blair Witch Project, The  1999\n",
      "8            Close Shave, A  1995\n",
      "9            Godfather, The  1972\n",
      " \n",
      "Wind&Deep Recommendations\n",
      "                                title  year\n",
      "0       Bridge on the River Kwai, The  1957\n",
      "1                D3: The Mighty Ducks  1996\n",
      "2                       Cool Runnings  1993\n",
      "3                           Beautiful  2000\n",
      "4                   Cold Comfort Farm  1995\n",
      "5                                 Big  1988\n",
      "6  Life Is Beautiful (La Vita  bella)  1997\n",
      "7                     King and I, The  1956\n",
      "8                      Godfather, The  1972\n",
      "9                             Sabrina  1954\n",
      "CPU times: user 324 ms, sys: 101 ms, total: 426 ms\n",
      "Wall time: 1min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fav_movies = ['Tinker Tailor Soldier Spy', 'Shawshank Redemption', 'Lord of the Rings']\n",
    "new_user_input(fav_movies = fav_movies, all_ratings = ratings, \n",
    "               movies = movies, spark_context = sc, sqlContext = sqlContext,\n",
    "               num_recs = 10, age = 26, gender = 'M', movies_gp = movies_gp, movies_df = movies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting favorite movie IDs\n",
      "Favorite movies in the available set\n",
      "         item_id                title  year\n",
      "item_id                                    \n",
      "1              1            Toy Story  1995\n",
      "3114        3114          Toy Story 2  1999\n",
      "1197        1197  Princess Bride, The  1987\n",
      "Adding ratings to full set\n",
      "Creating prediction set\n",
      "Formatting training and prediction dataframes for NCF\n",
      "Training NCF Model\n",
      "creating: createZooNeuralCF\n",
      "creating: createClassNLLCriterion\n",
      "creating: createMaxEpoch\n",
      "creating: createAdam\n",
      "creating: createDistriOptimizer\n",
      "Making Predictions\n",
      "\n",
      "NCF Recommendations\n",
      "                                               title  year\n",
      "0                                Usual Suspects, The  1995\n",
      "1                                Wrong Trousers, The  1993\n",
      "2                              To Kill a Mockingbird  1962\n",
      "3           Bicycle Thief, The (Ladri di biciclette)  1948\n",
      "4  Seven Samurai (The Magnificent Seven) (Shichin...  1954\n",
      "5                          Shawshank Redemption, The  1994\n",
      "6                                            Matilda  1996\n",
      "7                                     Godfather, The  1972\n",
      "8                                        Rear Window  1954\n",
      "9             Sunset Blvd. (a.k.a. Sunset Boulevard)  1950\n",
      " \n",
      "Wind&Deep Recommendations\n",
      "                                               title  year\n",
      "0                          Manchurian Candidate, The  1962\n",
      "1                                            Yojimbo  1961\n",
      "2  Seven Samurai (The Magnificent Seven) (Shichin...  1954\n",
      "3                                                Big  1988\n",
      "4                          Celebration, The (Festen)  1998\n",
      "5                                            Payback  1999\n",
      "6                                       Lost & Found  1999\n",
      "7                                     Godfather, The  1972\n",
      "8                                         Casablanca  1942\n",
      "9                                Maltese Falcon, The  1941\n",
      "CPU times: user 393 ms, sys: 126 ms, total: 519 ms\n",
      "Wall time: 1min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fav_movies = ['Frozen', 'Tangled', 'Oceans Eleven', 'Toy Story', 'The Princess Bride',  \n",
    "              'The Incredibles', 'Castle in the Sky', 'Monsters, Inc']\n",
    "new_user_input(fav_movies = fav_movies, all_ratings = ratings, \n",
    "               movies = movies, spark_context = sc, sqlContext = sqlContext,\n",
    "               num_recs = 10, age = 26, gender = 'M', movies_gp = movies_gp, movies_df = movies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting favorite movie IDs\n",
      "Favorite movies in the available set\n",
      "         item_id                title  year\n",
      "item_id                                    \n",
      "1              1            Toy Story  1995\n",
      "3114        3114          Toy Story 2  1999\n",
      "1197        1197  Princess Bride, The  1987\n",
      "Adding ratings to full set\n",
      "Creating prediction set\n",
      "Formatting training and prediction dataframes for NCF\n",
      "Training NCF Model\n",
      "creating: createZooNeuralCF\n",
      "creating: createClassNLLCriterion\n",
      "creating: createMaxEpoch\n",
      "creating: createAdam\n",
      "creating: createDistriOptimizer\n",
      "Making Predictions\n",
      "\n",
      "NCF Recommendations\n",
      "                       title  year\n",
      "0        Usual Suspects, The  1995\n",
      "1                  Cape Fear  1991\n",
      "2              Cool Runnings  1993\n",
      "3                  Beautiful  2000\n",
      "4                Blue Hawaii  1961\n",
      "5           Schindler's List  1993\n",
      "6  Shawshank Redemption, The  1994\n",
      "7                    Sanjuro  1962\n",
      "8             Close Shave, A  1995\n",
      "9             Godfather, The  1972\n",
      " \n",
      "Wind&Deep Recommendations\n",
      "                                title  year\n",
      "0                           Chinatown  1974\n",
      "1                       Cool Runnings  1993\n",
      "2                        General, The  1927\n",
      "3                         Blue Hawaii  1961\n",
      "4  Star Wars: Episode IV - A New Hope  1977\n",
      "5                           True Lies  1994\n",
      "6                             Sanjuro  1962\n",
      "7                      Godfather, The  1972\n",
      "8                  North by Northwest  1959\n",
      "9                  As Good As It Gets  1997\n",
      "CPU times: user 339 ms, sys: 88.2 ms, total: 427 ms\n",
      "Wall time: 1min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fav_movies = ['Frozen', 'Tangled', 'Oceans Eleven', 'Toy Story', 'The Princess Bride',  \n",
    "              'The Incredibles', 'Castle in the Sky', 'Monsters, Inc']\n",
    "new_user_input(fav_movies = fav_movies, all_ratings = ratings, \n",
    "               movies = movies, spark_context = sc, sqlContext = sqlContext,\n",
    "               num_recs = 10, age = 8, gender = 'F', movies_gp = movies_gp, movies_df = movies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting favorite movie IDs\n",
      "Favorite movies in the available set\n",
      "         item_id                                           title  year\n",
      "item_id                                                               \n",
      "1035        1035                             Sound of Music, The  1965\n",
      "1              1                                       Toy Story  1995\n",
      "3114        3114                                     Toy Story 2  1999\n",
      "1197        1197                             Princess Bride, The  1987\n",
      "572          572                                 Foreign Student  1994\n",
      "1196        1196  Star Wars: Episode V - The Empire Strikes Back  1980\n",
      "1210        1210      Star Wars: Episode VI - Return of the Jedi  1983\n",
      "260          260              Star Wars: Episode IV - A New Hope  1977\n",
      "2628        2628       Star Wars: Episode I - The Phantom Menace  1999\n",
      "904          904                                     Rear Window  1954\n",
      "1265        1265                                   Groundhog Day  1993\n",
      "2716        2716                                    Ghostbusters  1984\n",
      "520          520                       Robin Hood: Men in Tights  1993\n",
      "165          165                      Die Hard: With a Vengeance  1995\n",
      "1370        1370                                      Die Hard 2  1990\n",
      "1036        1036                                        Die Hard  1988\n",
      "Adding ratings to full set\n",
      "Creating prediction set\n",
      "Formatting training and prediction dataframes for NCF\n",
      "Training NCF Model\n",
      "creating: createZooNeuralCF\n",
      "creating: createClassNLLCriterion\n",
      "creating: createMaxEpoch\n",
      "creating: createAdam\n",
      "creating: createDistriOptimizer\n",
      "Making Predictions\n",
      "\n",
      "NCF Recommendations\n",
      "                                               title  year\n",
      "0                                Usual Suspects, The  1995\n",
      "1                                Wrong Trousers, The  1993\n",
      "2                                 Gone in 60 Seconds  2000\n",
      "3                                   Schindler's List  1993\n",
      "4  Seven Samurai (The Magnificent Seven) (Shichin...  1954\n",
      "5                    Love Is a Many-Splendored Thing  1955\n",
      "6                                     Close Shave, A  1995\n",
      "7                                            Foxfire  1996\n",
      "8                                     Godfather, The  1972\n",
      "9             Sunset Blvd. (a.k.a. Sunset Boulevard)  1950\n",
      " \n",
      "Wind&Deep Recommendations\n",
      "                                    title  year\n",
      "0           Bridge on the River Kwai, The  1957\n",
      "1               Manchurian Candidate, The  1962\n",
      "2                          Paths of Glory  1957\n",
      "3         One Flew Over the Cuckoo's Nest  1975\n",
      "4                      Lawrence of Arabia  1962\n",
      "5                               Mask, The  1994\n",
      "6                             City Lights  1931\n",
      "7                          Close Shave, A  1995\n",
      "8                                 Foxfire  1996\n",
      "9  Sunset Blvd. (a.k.a. Sunset Boulevard)  1950\n",
      "CPU times: user 356 ms, sys: 102 ms, total: 458 ms\n",
      "Wall time: 1min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fav_movies = ['The Sound of Music', 'Blackhawk Down', 'Pearl Harbor', 'Toy Story', 'The Princess Bride',  \n",
    "              'Foreign Student', 'Star Wars', 'The Shining', 'Rear Window', 'Groundhog Day', 'Ghostbusters', \n",
    "              'Robin Hood (1993)', 'Die Hard']\n",
    "new_user_input(fav_movies = fav_movies, all_ratings = ratings, \n",
    "               movies = movies, spark_context = sc, sqlContext = sqlContext,\n",
    "               num_recs = 10, age = 40, gender = 'M', movies_gp = movies_gp, movies_df = movies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
